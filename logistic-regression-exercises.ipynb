{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n",
    "\n",
    "1. Start by defining your baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/CODEUP/darden/CodeupClassroom/darden-classification-exercises/prepare.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['age'] = imputer.transform(test[['age']])\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = prepare.prep_titanic()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About X_ and y_\n",
    "\n",
    "X_(train, validate, test) needs to be a dataframe\n",
    "X_train can be defined with `train[[columns]]`, `train.drop(columns=[])` (or validate, or test)\n",
    "y_train can be a series with `train[col]`, `train.col` (or validate, or test)\n",
    "\n",
    "you only need to split it before you use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train = train[['age', 'survived']]\n",
    "demo_train2 = train[['age', 'pclass', 'survived']]\n",
    "\n",
    "X_demo_train = demo_train[['age']]\n",
    "X_demo_train = demo_train.drop(columns=['survived'])\n",
    "# below will not work in your algorithm! (e.g. LogisticRegresion.fit()) \n",
    "# X_demo_train = demo_train['age']\n",
    "# bc it needs to be a dataframe for X\n",
    "# ___________\n",
    "\n",
    "X_demo_train2 = demo_train[['age', 'pclass']]\n",
    "X_demo_train2 = demo_train.drop(columns=['survived'])\n",
    "\n",
    "\n",
    "y_demo_train = demo_train[['survived']]\n",
    "y_demo_train = demo_train['survived']\n",
    "y_demo_train = demo_train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.617706\n",
       "1    0.382294\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My baseline accuracy with no model: I will guess the passenger did not survive and on our training data, I would get 62% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.73460016 -0.0160103  -0.44806166 -0.13603857  0.00431481 -0.75917746\n",
      "  -2.25825746  0.50855606  0.24301123]]\n",
      "Index(['pclass', 'age', 'sibsp', 'parch', 'fare', 'alone', 'sex_male',\n",
      "       'embarked_Q', 'embarked_S'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logit1 = LogisticRegression()\n",
    "\n",
    "X_train1 = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "logit1 = logit1.fit(X_train1, y_train)\n",
    "print(logit1.coef_)\n",
    "print(X_train1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = logit1.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7987927565392354"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit1.score(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model: 80% accuracy, much better than guessing alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create another model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02427755  0.00415002 -0.83379906]]\n",
      "Index(['age', 'fare', 'pclass'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train2 = train[['age', 'fare', 'pclass']]\n",
    "y_train = train.survived\n",
    "\n",
    "logit2 = LogisticRegression()\n",
    "logit2 = logit2.fit(X_train2, y_train)\n",
    "\n",
    "print(logit2.coef_)\n",
    "print(X_train2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7082494969818913"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2.score(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one did not perform nearly as well as model 1, 71% vs. 80% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  sex_male  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1         1   \n",
       "337         1       1  41.000000      0      0  134.5000      1         0   \n",
       "50          0       3   7.000000      4      1   39.6875      0         1   \n",
       "218         1       1  32.000000      0      0   76.2917      1         0   \n",
       "31          1       1  29.916875      1      0  146.5208      0         0   \n",
       "\n",
       "     embarked_Q  embarked_S  \n",
       "583           0           0  \n",
       "337           0           0  \n",
       "50            0           1  \n",
       "218           0           0  \n",
       "31            0           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01431495  0.00310367 -0.82578862 -2.29993317]]\n",
      "Index(['age', 'fare', 'pclass', 'sex_male'], dtype='object')\n",
      "0.7867203219315896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train3 = train[['age', 'fare', 'pclass', 'sex_male']]\n",
    "y_train = train.survived\n",
    "\n",
    "logit3 = LogisticRegression()\n",
    "logit3 = logit3.fit(X_train3, y_train)\n",
    "\n",
    "print(logit3.coef_)\n",
    "print(X_train3.columns)\n",
    "print(logit3.score(X_train3, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIDE NOTE\n",
    "# demonstrating the weights with different values\n",
    "# a weight of .003 with a $500 fare is not much different \n",
    "# than a weight of 2.3 with a 1 for sex_male\n",
    "\n",
    "500*.003 \n",
    "1*2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = train[['sex_male']]\n",
    "y_train = train.survived\n",
    "\n",
    "def my_logit(X_train):\n",
    "    my_logit = LogisticRegression()\n",
    "    my_logit = my_logit.fit(X_train, y_train)\n",
    "    return my_logit, my_logit.coef_, my_logit.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.34811852]] 0.7847082494969819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logit4, coefs, accuracy = my_logit(X_train4)\n",
    "print(coefs, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'alone',\n",
       "       'sex_male', 'embarked_Q', 'embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5552899  -0.06432213 -1.74410376  0.14466641 -0.32118676]] 0.6941649899396378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train5 = train[['sibsp', 'parch', 'alone', 'embarked_Q', 'embarked_S']]\n",
    "\n",
    "logit5, coefs, accuracy = my_logit(X_train5)\n",
    "print(coefs, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26318011 -2.27623838 -0.83010265]] 0.7847082494969819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train6 = train[['alone', 'sex_male', 'pclass']]\n",
    "\n",
    "logit6, coefs, accuracy = my_logit(X_train6)\n",
    "print(coefs, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use you best 3 models to predict and evaluate on your validate sample.\n",
    "\n",
    "We will use models 1 (all vars), 4 (sex_male), & 6 (alone, pclass, sex_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780373831775701 0.7663551401869159 0.7429906542056075\n"
     ]
    }
   ],
   "source": [
    "X_validate1 = validate.drop(columns=['survived'])\n",
    "X_validate4 = validate[['sex_male']]\n",
    "X_validate6 = validate[['alone', 'pclass', 'sex_male']]\n",
    "\n",
    "y_validate = validate.survived\n",
    "\n",
    "acc1 = logit1.score(X_validate1, y_validate)\n",
    "acc4 = logit4.score(X_validate4, y_validate)\n",
    "acc6 = logit6.score(X_validate6, y_validate)\n",
    "\n",
    "print(acc1, acc4, acc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: All Vars:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       132\n",
      "           1       0.75      0.65      0.69        82\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "y4: Sex_male only:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       132\n",
      "           1       0.71      0.67      0.69        82\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       214\n",
      "   macro avg       0.75      0.75      0.75       214\n",
      "weighted avg       0.76      0.77      0.77       214\n",
      "\n",
      "y6: Age, Pclass, Sex_male:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       132\n",
      "           1       1.00      0.33      0.50        82\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       214\n",
      "   macro avg       0.85      0.66      0.66       214\n",
      "weighted avg       0.82      0.74      0.70       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y1_pred = logit1.predict(X_validate1)\n",
    "y4_pred = logit4.predict(X_validate4)\n",
    "y6_pred = logit6.predict(X_validate6)\n",
    "\n",
    "print(\"y1: All Vars:\\n\", classification_report(y_validate, y1_pred))\n",
    "\n",
    "print(\"y4: Sex_male only:\\n\", classification_report(y_validate, y4_pred))\n",
    "\n",
    "print(\"y6: Age, Pclass, Sex_male:\\n\", classification_report(y_validate, y6_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "\n",
    "We will use the first model, the one with all X variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8202247191011236\n",
      "test report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       110\n",
      "           1       0.78      0.74      0.76        68\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       178\n",
      "   macro avg       0.81      0.80      0.81       178\n",
      "weighted avg       0.82      0.82      0.82       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test1 = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "test_acc = logit1.score(X_test1, y_test)\n",
    "y1_pred = logit1.predict(X_test1)\n",
    "\n",
    "print(test_acc)\n",
    "print(\"test report:\\n\", classification_report(y_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus1 How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "Bonus2: How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "Bonus3: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
